# -*- coding: utf-8 -*-
"""imdb web scraping with BeautifulSoup

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QjCqbUkQmcowoWZ9GyfLwt24L1lDzpHU
"""

#import the relevant libraries and modules
from urllib.request import urlopen as uReq
from bs4 import BeautifulSoup as soup

#get the webpage url
my_url='https://www.imdb.com/list/ls050745379/'

#download the webpage
uClient=uReq(my_url)

page_html=uClient.read()
uClient.close()

#parse the html
page_soup=soup(page_html,"html.parser")

#grabs each actor's whole details
containers1=page_soup.findAll("div",{"class":"lister-item mode-detail"})

#lets see the number of actor's it finds
print(len(containers1))

#let us see the html elements inside each container
containers1[0]



#let us create the .csv file to store the information
filename="actors.csv"
f=open(filename,"w") #w is for write mode

#create headers for the csv file
headers="actor_name,actor_image,actor_movie,actor_info\n"

#write the headers
f.write(headers)

for container1 in containers1:
  #gets the image url of the actors
   actor_image= container1.div.img["src"]


  #gets the names of the actors
   actor_name=container1.div.img["alt"]

  #gets the names of one movie where the actor has acted in
   movie_title=container1.findAll("p",{"class":"text-muted text-small"})
   movie_acted=movie_title[0].a.text

  #get information about actors
   t=container1.findAll("p",class_=False,id=False)
   about_actor=t[0].text



#write the rest of the data inside the csv file
   f.write(actor_name + "," +'"{}"'.format(actor_image) + "," +'"{}"'.format (movie_acted)+ "," +'"{}"'.format(about_actor) + "\n" )
   #using '"{}"'.format wraps with double quotes and prevents creation of additional columns when a comma is encountered as comma is the default delimiter in csv format

#close the file
f.close()

#download the csv file into local machine
from google.colab import files
files.download('actors.csv')






"""# New Section"""
